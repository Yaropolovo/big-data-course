beginner.how_many_items_in_hdfs:
    stdin: 9
intermediate.hdfs_list_recursively:
    stdin: "hdfs dfs -ls -R /data/wiki"
intermediate.hdfs_list_recursively_human_readable:
    stdin: "hdfs dfs -ls -h -R /data/wiki"
intermediate.hdfs_file_replication_factor:
    stdin: 3
intermediate.hdfs_folder_replication_factor:
    stdin: 0
intermediate.hdfs_describe_size:
    stdin: "actual"
intermediate.hdfs_cumulative_size:
    stdin: "hdfs dfs -du -s -h /data/wiki"
intermediate.hdfs_create_folder:
    stdin: "hdfs dfs -mkdir /user/bdb2c2022q2_yaropolov/bdb2c2022q2_yaropolov_5779"
intermediate.hdfs_create_nested_folder:
    stdin: "hdfs dfs -mkdir -p /user/bdb2c2022q2_yaropolov/bdb2c2022q2_yaropolov_5779/second/third"
intermediate.hdfs_remove_nested_folders:
    stdin: "hdfs dfs -rm -r /user/bdb2c2022q2_yaropolov/bdb2c2022q2_yaropolov_5779"
intermediate.hdfs_trash_behavior:
    stdin: |-
        "hdfs dfs -rm -r -skipTrash /user/bdb2c2022q2_yaropolov/bdb2c2022q2_yaropolov_5779"
        
        .Trash is a special directory in user's home directory. Instead of removal files are moved 
        into .trash and stored where for a fs.trash.interval period. Files in .trash are permanently 
        deleted after expiration. Files are still require space while beeing stored into .trash. 
intermediate.hdfs_create_empty_file:
    stdin: "hdfs dfs -touchz /user/bdb2c2022q2_yaropolov/empty_file"
intermediate.hdfs_create_small_file:
    stdin: |-
        truncate -s 2K small_test_file.txt
        hdfs dfs -put small_test_file.txt /user/bdb2c2022q2_yaropolov
intermediate.hdfs_output_file:
    stdin: "hdfs dfs -cat small_test_file.txt"
intermediate.hdfs_output_file_end:
    stdin: "hdfs dfs -tail small_test_file.txt"
intermediate.hdfs_output_file_start:
    stdin: "hdfs dfs -cat small_test_file.txt | head"
intermediate.hdfs_tail_vs_unix_tail:
    stdin: "tail --bytes=1024 small_test_file.txt"
intermediate.hdfs_copy_file:
    stdin: "hdfs dfs -cp small_test_file.txt small_test_file_copy.txt"
intermediate.hdfs_move_file:
    stdin: |-
        hdfs dfs -mkdir /user/bdb2c2022q2_yaropolov/temp_dir/
        hdfs dfs -mv small_test_file_copy.txt /user/bdb2c2022q2_yaropolov/temp_dir/
intermediate.hdfs_download_and_concatenate:
    stdin: "hdfs dfs -getmerge small_test_file.txt merged_small_test_file.txt"
advanced.hdfs_set_file_replication:
    stdin: |-
        hdfs dfs -setrep -w 4 small_test_file.txt
        Before testing I've expected that decreasing would be faster than increasing cause:
        1) deletion of replica is physically faster than creation; 
        2) changes in meta information (namenode) seems approximately equal
        I've seen no significant difference during test. For the very small testing file from previous section it took: 2->3 9sec; 3->4 10sec; 4->5 10sec; 5->3 9sec.
        However, during tests there was a warning message: "the waiting time may be long for DECREASING the number of replications". 
        I still doesn't understand why increasing might be faster but I will figure out :)
advanced.hdfs_get_files_and_block:
    stdin: "hdfs fsck test_updated.bash_history -files -blocks -locations"
advanced.hdfs_get_block_information:
    stdin: "hdfs fsck -blockId blk_1106590346"
advanced.hdfs_dfs_architecture:
    stdin: |-
        hdfs fsck test_updated.bash_history -files -blocks -locations
        sudo -i -u hdfsuser
        ssh brain-node3.bigdatateam.org
        find /srv/disk1/ -name blk_1106590346
        tail /srv/disk1/hadoop/datanode/current/BP-981064612-78.46.171.101-1581506447497/current/finalized/subdir21/subdir26/blk_1106590346
        exit
        hdfs dfs -ls /data/namenode_example/current
        hdfs dfs -cat /data/namenode_example/current/fsimage_0000000000030725661
        hdfs dfs -cat /data/namenode_example/current/edits_0000000000029536578-0000000000030039785
advanced.webhdfs_read_100B:
    stdin: |-
        curl -i "http://brain-node4.bigdatateam.org:50075/webhdfs/v1/user/bdb2c2022q2_yaropolov/test_updated.bash_history?op=OPEN&namenoderpcaddress=brain-master.bigdatateam.org:8020&length=100"
advanced.webhdfs_curl_follow_redirects:
    stdin: |-
        curl -i -L "http://brain-master:50070/webhdfs/v1/user/bdb2c2022q2_yaropolov/test_updated.bash_history?op=OPEN"
advanced.webhdfs_get_file_detailed_information:
    stdin: |-
        curl -i -L "http://brain-master:50070/webhdfs/v1/user/bdb2c2022q2_yaropolov/test_updated.bash_history?op=GETFILESTATUS"
advanced.webhdfs_change_file_replication:
    stdin: |-
        curl -i -X PUT "http://brain-master:50070/webhdfs/v1/user/bdb2c2022q2_yaropolov/test_updated.bash_history?user.name=bdb2c2022q2_yaropolov&op=SETREPLICATION&replication=4"
advanced.webhdfs_append_to_file:
    stdin: |-
        curl -i -L -X POST -T test.bash_history "http://brain-master:50070/webhdfs/v1/user/bdb2c2022q2_yaropolov/test_updated.bash_history?user.name=bdb2c2022q2_yaropolov&op=APPEND"
